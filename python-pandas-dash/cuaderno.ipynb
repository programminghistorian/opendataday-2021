{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('datamooc': conda)",
   "metadata": {
    "interpreter": {
     "hash": "81c2c383596c9be05326fd2639876d79d2aa36abbad0d42dcc9c2ac2e75fda39"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Open Data Day\n",
    "## Visualización de datos abiertos con Python >> Pandas >> Dash\n",
    "## Pero primero, algunas aclaraciones\n",
    "\n",
    "<img src=\"imgs/python.jpg\">\n",
    "<img src=\"imgs/pandas.jpg\">\n",
    "<img src=\"imgs/plotly_dash.jpg\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Esto no es PowerPoint ¿dónde estamos ahora?\n",
    "\n",
    "<img src=\"imgs/Jupyter.jpg\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## ¿Cómo ejecutar el notebook?\n",
    "\n",
    "En **Colab** (es necesaria una cuenta de Google):\n",
    "\n",
    "1. Ir a la dirección https://colab.research.google.com/\n",
    "2. Seleccionar la pestaña GitHub\n",
    "3. Ingresa la URL correspondiente a Programming Historian >> Open Data Day: https://github.com/programminghistorian/opendataday-2021\n",
    "4. Seleccionar el notebook de la ruta `python-pandas-dash/cuaderno.ipynb`\n",
    "5. Para ejecutar las casillas será necesario autenticarse con una cuenta de Google.\n",
    "\n",
    "En **binder** (es probable que se encuentren algunos bugs y se tarde un poco en cargar):\n",
    "\n",
    "1. Ir a la dirección https://mybinder.org/\n",
    "2. Escribir la dirección del repositorio https://github.com/programminghistorian/opendataday-2021 en la casilla \"GitHub repository name or URL\"\n",
    "3. Ejecutar en el botón `launch`\n",
    "4. Abrir el directorio `python-pandas-dash`\n",
    "5. Abrir el archivo `cuaderno.ipynb`\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# ¡Basta de preliminares! ¡A la data!\n",
    "## >> ¿Open Data what?\n",
    "\n",
    "<img src=\"imgs/datos-abiertos-1.png\">\n",
    "\n",
    "* Principio del gobierno digital y abierto\n",
    "* Datos disponibles para todos los ciudadanos y ciudadanas\n",
    "* Datos oficiales, confiables y verificables de instituciones públicas\n",
    "\n",
    "### >> La información no está estructurada tal como la quisieramos tener.\n",
    "\n",
    "* No todos los datos están estructurados.\n",
    "* Abiertos no siempre se entienden como analizables.\n",
    "* En ocasiones, datos abiertos se entiendes como informes abiertos. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Escoger una fuente de datos\n",
    "\n",
    "<img src=\"imgs/tipos_de_archivo.jpg\">\n",
    "\n",
    "\"Icons made by Freepik, Smashicons, and Smartline from [www.flaticon.com]\"\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## ¿Qué datos usaremos para este ejercicio?\n",
    "\n",
    "Vamos a tomar una tabla estadística de la educación preescolar, básica y media por departamento en Colombia. Esta información la obtenemos de la siguiente dirección: https://www.datos.gov.co/Educaci-n/MEN_ESTADISTICAS_EN_EDUCACION_EN_PREESCOLAR-B-SICA/ji8i-4anb\n",
    "\n",
    "La descripción de este conjunto de datos es la siguiente:\n",
    "\n",
    "> El conjunto de datos contiene los principales indicadores de los niveles preescolar, básica y media discriminados por Departamento desde el año 2011 hasta 2019 definitiva oficial.\n",
    "\n",
    "> Este conjunto de datos se puede relacionar con el de matrícula en educación preescolar, básica y media donde se presenta la caracterización de los estudiantes que permiten obtener información para comprender el comportamiento de los indicadores\n",
    "\n",
    "En primer lugar, vamos a incluir en una *variable* la ruta a los datos:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.datos.gov.co/api/views/ji8i-4anb/rows.csv'\n",
    "\n",
    "print(url)"
   ]
  },
  {
   "source": [
    "### ¿Qué hicimos en este paso?\n",
    "\n",
    "Simplemente *declaramos* la dirección url en la que se encuentra el archivo csv (no la página web ¡muy importante!). \n",
    "\n",
    "En este caso no hemos descargado el objeto (el archivo `csv`), solamente escribimos la dirección de su ubicación."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Preparemos el terreno para realizar nuestras actividades\n",
    "\n",
    "Necesitaremos asegurarnos de tener instalados en nuestros ambientes algunas *librerías* que nos ayudarán a procesar los datos:\n",
    "\n",
    "Pandas: importa los datos y permite procesarlos fácilmente.\n",
    "Plotly: una librería para visualizar datos de manera interactiva y agradable.\n",
    "\n",
    "También instalaremos `jupyter-dash`, una librería que nos permitirá visualizar los datos directamente en nuestro Notebook. \n",
    "\n",
    "La velocidad de instalación de los paquetes depende del entorno desde el cual se esté ejecutando; en particular, la librería `jupyter-dash` es la más pesada. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install plotly\n",
    "!pip install jupyter-dash"
   ]
  },
  {
   "source": [
    "# ¿Cómo importar datos para ser procesados?\n",
    "\n",
    "## La forma relativamente fácil\n",
    "\n",
    "Con las librerías nativas de python `csv` y `urllib.request`\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "import urllib.request as ur\n",
    "import csv\n",
    "\n",
    "r = ur.urlopen(url)\n",
    "lineas = [l.decode('utf-8') for l in r.readlines()]\n",
    "\n",
    "archivo_csv = csv.reader(lineas)\n",
    "\n",
    "for r in archivo_csv:\n",
    "    print(r)"
   ]
  },
  {
   "source": [
    "## La manera extremadamente fácil\n",
    "\n",
    "Con `pandas`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(url)\n",
    "df.head()"
   ]
  },
  {
   "source": [
    "## Ahora, conozcamos un poco sobre cómo están estructurados nuestros datos\n",
    "\n",
    "### DataFrame\n",
    "\n",
    "Al recuperar los datos, `pandas` transforma la información en un tipo de objeto llamado `DataFrame`, que es básicamente una matriz de datos en la que cada fila corresponde a un objeto y cada columna a una variable.\n",
    "\n",
    "Los DataFrames pueden ser modificados de manera dinámica, pero se deben seguir ciertas reglas para evitar que la información se elimine o cambie de forma indeseada.\n",
    "\n",
    "Podemos comprobar que nuestro archivo `csv` ahora es un DataFrame si imprimimos el tipo de la variable `df`:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(df))"
   ]
  },
  {
   "source": [
    "\n",
    "\n",
    "### Tamaño\n",
    "\n",
    "* ¿Cuántas filas y columnas tiene esta tabla?\n",
    "\n",
    "Para saberlo, utilizaremos la función `shape` de pandas."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tamagno = df.shape\n",
    "num_filas = tamagno[0]\n",
    "num_columns = tamagno[1]\n",
    "\n",
    "print(tamagno)\n",
    "print(\"Esta tabla tiene {} filas y {} columnas\".format(num_filas, num_columns))"
   ]
  },
  {
   "source": [
    "^ la función `shape` regresa un tipo de archivo llamado *tuple* o *tupla*, que consiste en una lista ordenada de objetos. Podemos comprobarlo simplemente imprimiendo el tipo de dato:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(tamagno))"
   ]
  },
  {
   "source": [
    "### ¿Cuáles columnas tenemos en nuestro DataFrame?\n",
    "\n",
    "Para saber el nombre de cada columna (y poder hacer búsquedas posteriormente) podemos utilizar la función `columns` de pandas:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "source": [
    "### ¿Qué datos tenemos en el DataFrame?\n",
    "\n",
    "Ahora sabemos el tamaño del DataFrame y el nombre de sus columnas. Pero, para hacer operaciones (como sumar, restar, hallar medias, etc.) tendremos que identificar cuáles son los tipos de datos que tenemos en nuestro DataFrame.\n",
    "\n",
    "Para ello, usaremos la función `dtypes` de pandas:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "source": [
    "^ Analiza los tipos de datos que tenemos en el DataFrame:\n",
    "\n",
    "* int64 = números enteros\n",
    "* float64 = números decimales\n",
    "* object = objeto de pandas (puede ser un diccionario, un numpy.array, una lista...)\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Pandas incluso nos permite hacer análisis muy rápidos de la información, como por ejemplo, hallar la desviación estándar de cada columna (en la que existan datos de intervalo):"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.std()"
   ]
  },
  {
   "source": [
    "# Manipular la información del DataFrame\n",
    "\n",
    "## ¿Qué información hay en una columna específica?\n",
    "\n",
    "Para ver qué información tiene una columna específica vamos a utilizar el siguiente método:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_nombre = df['DEPARTAMENTO']\n",
    "\n",
    "col_nombre[:10]"
   ]
  },
  {
   "source": [
    "^ ¿Qué información regresa este método?\n",
    "\n",
    "Intenta con otras columnas y revisa qué información podemos obtener."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribe aquí tu código >>\n",
    "\n"
   ]
  },
  {
   "source": [
    "## ¿Cómo podemos acceder a información de las filas?\n",
    "\n",
    "### El método `iloc`\n",
    "\n",
    "Con este método podemos acceder a una fila o serie de filas de acuerdo con su índice (0 >> n)\n",
    "\n",
    "Por ejemplo:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acceder a la fila con índice = 5\n",
    "lista_segmentada = df.iloc[5]\n",
    "lista_segmentada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acceder a las filas 10 a 20\n",
    "\n",
    "lista_segmentada = df.iloc[10:20]\n",
    "lista_segmentada"
   ]
  },
  {
   "source": [
    "^ ¿Qué información regresa este método? \n",
    "\n",
    "Pruébalo por tí mismo:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribe aquí tu código"
   ]
  },
  {
   "source": [
    "### El método `loc`\n",
    "\n",
    "Este método es bastante útil para encontrar coincidencias en una serie. Es similar al query en SQL ```SELECT * FROM `tabla` WHERE `columna` = 'clave'```\n",
    "\n",
    "Se escribe de la siguiente manera:\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "busqueda = df.loc[df['DEPARTAMENTO'] == \"Santander\"]\n",
    "busqueda\n"
   ]
  },
  {
   "source": [
    "¿Y si queremos ver por departamento y año?\n",
    "\n",
    "Utilizamos el mismo método (`loc`) pero ahora buscamos dos valores. Si lo verbalizamos es como pedirle a la máquina:\n",
    "\n",
    "Búscame en el DataFrame todos los valores en los que el departamento sea 'Santander' y el año sea igual a 2019. Recordemos que la columna 'AÑO' está compuesta por datos en `int64`, así que tendremos que escribir el año **sin comillas**.\n",
    "\n",
    "En código será el siguiente:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agno_loc = df.loc[(df['DEPARTAMENTO'] == 'Santander') & (df['AÑO'] == 2019)]\n",
    "agno_loc"
   ]
  },
  {
   "source": [
    "Ahora, intenta regresar los valores correspondientes a un año completo:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribe aquí tu código:\n",
    "\n"
   ]
  },
  {
   "source": [
    "# ¡A visualizar!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Con estos datos, podemos hacer nuestra primera visualización. Por ejemplo, ver la tasa de matriculación por año en un departamento específico. \n",
    "\n",
    "La manera más sencilla de hacerlo es utilizando la librería `Matplotlib` que se instala al mismo tiempo que `pandas`. Para hacer la gráfica, primero tenemos que definir nuestro DataFrame:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bogota = df.loc[df['DEPARTAMENTO'] == 'Bogotá, D.C.']\n",
    "bogota"
   ]
  },
  {
   "source": [
    "Ahora, vamos a realizar un gráfico de barras que muestre la tasa de matriculación entre los años 2011 y 2019:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En este primer ejemplo, usamos la función `plot`, que integra Matplotlib.pyplot en pandas\n",
    "\n",
    "bogota.plot.bar(x='AÑO', y='TASA_MATRICULACIÓN_5_16', rot=70, title='Tasa de matriculación en Bogotá (2011-2019')\n",
    "plot.show()"
   ]
  },
  {
   "source": [
    "También podemos hacer una comparativa de la cobertura con una gráfica de barras agrupadas. \n",
    "\n",
    "En primer lugar, construyamos un DataFrame que contenga solamente los resultados que usaremos:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bogota_cobertura = bogota.groupby('AÑO').sum()[['COBERTURA_NETA_TRANSICIÓN', 'COBERTURA_NETA_PRIMARIA', 'COBERTURA_NETA_SECUNDARIA', 'COBERTURA_NETA_MEDIA']]\n",
    "bogota_cobertura = bogota_cobertura.sort_values('AÑO')\n",
    "bogota_cobertura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# definimos la figura\n",
    "fig, ax = plt.subplots(1, figsize=(16, 6))\n",
    "\n",
    "# establecemos los valores del eje x\n",
    "x = np.arange(0, len(bogota_cobertura.index))\n",
    "\n",
    "# escribimos las barras\n",
    "plt.bar(x - 0.3, bogota_cobertura['COBERTURA_NETA_TRANSICIÓN'], width = 0.2, color = '#1D2F6F')\n",
    "plt.bar(x - 0.1, bogota_cobertura['COBERTURA_NETA_PRIMARIA'], width = 0.2, color = '#8390FA')\n",
    "plt.bar(x + 0.1, bogota_cobertura['COBERTURA_NETA_SECUNDARIA'], width = 0.2, color = '#6EAF46')\n",
    "plt.bar(x + 0.3, bogota_cobertura['COBERTURA_NETA_MEDIA'], width = 0.2, color = '#FAC748')\n",
    "\n",
    "# eliminar líneas de la caja de la visualización\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "\n",
    "# leyendas de los ejes x y\n",
    "plt.ylabel('Cobertura neta')\n",
    "plt.xticks(x, bogota_cobertura.index)\n",
    "\n",
    "# líneas de la cuadrícula\n",
    "ax.set_axisbelow(True)\n",
    "ax.yaxis.grid(color='gray', linestyle='dashed', alpha=0.2)\n",
    "\n",
    "# Título y leyenda\n",
    "plt.title('Cobertura neta de matrícula en Bogotá (2011-2019)')\n",
    "plt.legend(['transición', 'primaria', 'secundaria', 'media'], loc='upper left', ncol = 4)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "source": [
    "De manera similar, podemos hacer barras horizontales y agrupadas como las siguientes:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "campos = ['COBERTURA_NETA_TRANSICIÓN', 'COBERTURA_NETA_PRIMARIA', 'COBERTURA_NETA_SECUNDARIA', 'COBERTURA_NETA_MEDIA']\n",
    "colores = ['#1D2F6F', '#8390FA', '#6EAF46', '#FAC748']\n",
    "etiquetas = ['transición', 'primaria', 'secundaria', 'media']\n",
    "\n",
    "# Figura y ejes\n",
    "fig, ax = plt.subplots(1, figsize=(12, 10))\n",
    "\n",
    "# barras\n",
    "left = len(bogota_cobertura) * [0]\n",
    "for idx, name in enumerate(campos):\n",
    "    plt.barh(bogota_cobertura.index, bogota_cobertura[name], left = left, color=colores[idx])\n",
    "    left = left + bogota_cobertura[name]\n",
    "\n",
    "# título, leyenda y etiquetas\n",
    "plt.title('Cobertura neta de matrícula en Bogotá (2011-2019)')\n",
    "plt.legend(etiquetas, bbox_to_anchor=([0.55, 1, 0, 0]), ncol=4, frameon=False)\n",
    "plt.xlabel('Cobertura neta')\n",
    "\n",
    "# Remover los bordes\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "\n",
    "# Ajustar los límites y escribir la cuadrícula\n",
    "ax.set_axisbelow(True)\n",
    "ax.xaxis.grid(color='gray', linestyle='dashed')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "source": [
    "¿puedes hacer una gráfica similar con otro departamento?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribe aquí tu código\n",
    "\n"
   ]
  },
  {
   "source": [
    "# ¿Cómo podemos hacer algo más complejo (de manera más sencilla)?\n",
    "\n",
    "Con Matplotlib es posible hacer toda clase de visualizaciones ([por ejemplo](https://www.machinelearningplus.com/plots/top-50-matplotlib-visualizations-the-master-plots-python/)), pero una forma sencilla, dinámica y lista para publicar es a través de `plotly - Dash`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter(df, x='POBLACIÓN_5_16', y='TASA_MATRICULACIÓN_5_16', color='DEPARTAMENTO', size='TASA_MATRICULACIÓN_5_16', hover_data=['POBLACIÓN_5_16'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupyter_dash import JupyterDash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necesario si corre en Binder\n",
    "\n",
    "JupyterDash.infer_jupyter_proxy_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir la aplicación\n",
    "\n",
    "app = JupyterDash(__name__)\n",
    "\n",
    "server = app.server\n",
    "\n",
    "app.layout = html.Div([\n",
    "    dcc.Graph(figure=fig)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.run_server(mode=\"inline\")"
   ]
  },
  {
   "source": [
    "## Pero es mejor aún cuando podemos animar nuestras visualizaciones\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = px.data.gapminder()\n",
    "fig = px.scatter(df, x=\"gdpPercap\", y=\"lifeExp\", animation_frame=\"year\", animation_group=\"country\",\n",
    "           size=\"pop\", color=\"continent\", hover_name=\"country\",\n",
    "           log_x=True, size_max=55, range_x=[100,100000], range_y=[25,90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir la aplicación\n",
    "\n",
    "app = JupyterDash(__name__)\n",
    "\n",
    "server = app.server\n",
    "\n",
    "app.layout = html.Div([\n",
    "    dcc.Graph(figure=fig)\n",
    "])\n",
    "\n",
    "app.run_server(mode=\"inline\")"
   ]
  },
  {
   "source": [
    "¿Tienes otros datos de los cuales puedas encontrar correlaciones?\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribe aquí tu código"
   ]
  },
  {
   "source": [
    "# Referencias\n",
    "\n",
    "## Documentación\n",
    "\n",
    "* [The Programming Historian: Python](https://programminghistorian.org/es/lecciones/?topic=python)\n",
    "* [pandas documentation](https://pandas.pydata.org/pandas-docs/stable/index.html)\n",
    "* [plotly open source graphing libraries](https://plotly.com/python/)\n",
    "* [dash open-source](https://dash.plotly.com/)\n",
    "\n",
    "\n",
    "## Bibliografía\n",
    "\n",
    "* McKinney, Wes. *Python for data analysis: data wrangling with pandas, NumPy, and IPython*. Second edition, O’Reilly Media, Inc, 2018.\n",
    "* Pajankar, Ashwin. *Practical Python Data Visualization: A Fast Track Approach to Learning Data Visualization with Python*. 2021.\n",
    "* Stepanek, y Suresh John. *Thinking in Pandas*. Apress, 2020. Open WorldCat, https://link.springer.com/10.1007/978-1-4842-5839-2.\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}