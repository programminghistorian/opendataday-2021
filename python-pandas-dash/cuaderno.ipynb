{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('datamooc': conda)",
   "metadata": {
    "interpreter": {
     "hash": "81c2c383596c9be05326fd2639876d79d2aa36abbad0d42dcc9c2ac2e75fda39"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Open Data Day\n",
    "## Visualización de datos abiertos con Python >> Pandas >> Dash\n",
    "\n",
    "<img src=\"imgs/python.jpg\">\n",
    "<img src=\"imgs/pandas.jpg\">\n",
    "<img src=\"imgs/plotly_dash.jpg\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### >> ¿Open Data what?\n",
    "\n",
    "<img src=\"imgs/datos-abiertos-1.png\">\n",
    "\n",
    "* Principio del gobierno digital y abierto\n",
    "* Datos disponibles para todos los ciudadanos y ciudadanas\n",
    "* Datos oficiales, confiables y verificables de instituciones públicas\n",
    "\n",
    "### >> La información no está estructurada tal como la quisieramos tener.\n",
    "\n",
    "* No todos los datos están estructurados.\n",
    "* Abiertos no siempre se entienden como analizables.\n",
    "* En ocasiones, datos abiertos se entiendes como informes abiertos. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Escoger una fuente de datos\n",
    "\n",
    "<img src=\"imgs/tipos_de_archivo.jpg\">\n",
    "\n",
    "\"Icons made by Freepik, Smashicons, and Smartline from [www.flaticon.com]\"\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://datos.cdmx.gob.mx/dataset/3abd0da2-38e4-4c73-b386-3e0ef7b48d55/resource/634a7992-5aa3-4e6c-a081-191ef4dbb463/download/diagnostico-cdmx_2015_educacion.csv'\n",
    "\n",
    "print(url)"
   ]
  },
  {
   "source": [
    "### ¿Qué hicimos en este paso?\n",
    "\n",
    "Simplemente *declaramos* la dirección url en la que se encuentra el archivo csv (no la página web ¡muy importante!). \n",
    "\n",
    "En este caso no hemos descargado el objeto (el archivo `csv`), solamente escribimos la dirección de su ubicación."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Preparemos el terreno para realizar nuestras actividades\n",
    "\n",
    "Necesitaremos asegurarnos de tener instalados en nuestros ambientes algunas *librerías* que nos ayudarán a procesar los datos:\n",
    "\n",
    "Pandas: importa los datos y permite procesarlos fácilmente.\n",
    "Plotly: una librería para visualizar datos de manera interactiva y agradable.\n",
    "\n",
    "También instalaremos `jupyter-dash`, una librería que nos permitirá visualizar los datos directamente en nuestro Notebook. \n",
    "\n",
    "La velocidad de instalación de los paquetes depende del entorno desde el cual se esté ejecutando; en particular, la librería `jupyter-dash` es la más pesada. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install plotly\n",
    "!pip install jupyter-dash"
   ]
  },
  {
   "source": [
    "# ¿Cómo importar datos para ser procesados?\n",
    "\n",
    "## La forma relativamente fácil\n",
    "\n",
    "Con las librerías nativas de python `csv` y `urllib.request`\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "import urllib.request as ur\n",
    "import csv\n",
    "\n",
    "r = ur.urlopen(remoto)\n",
    "lineas = [l.decode('utf-8') for l in r.readlines()]\n",
    "\n",
    "archivo_csv = csv.reader(lineas)\n",
    "\n",
    "for r in archivo_csv:\n",
    "    print(r)"
   ]
  },
  {
   "source": [
    "## La manera extremadamente fácil\n",
    "\n",
    "Con `pandas`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(remoto)\n",
    "print(df.head())"
   ]
  },
  {
   "source": [
    "## Ahora, conozcamos un poco sobre cómo están estructurados nuestros datos\n",
    "\n",
    "### DataFrame\n",
    "\n",
    "Al recuperar los datos, `pandas` transforma la información en un tipo de objeto llamado `DataFrame`, que es básicamente una matriz de datos en el que cada fila corresponde a un objeto y cada columna a una variable.\n",
    "\n",
    "Los DataFrames pueden ser modificados de manera dinámica, pero se deben seguir ciertas reglas para evitar que la información se elimine o cambie de forma indeseada.\n",
    "\n",
    "Podemos comprobar que nuestro archivo `csv` ahora es un DataFrame si imprimimos el tipo de la variable `df`:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(df))"
   ]
  },
  {
   "source": [
    "\n",
    "\n",
    "### Tamaño\n",
    "\n",
    "* ¿Cuántas filas y columnas tiene esta tabla?\n",
    "- Para eso, utilizaremos la función `shape` de pandas."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tamagno = df.shape\n",
    "num_filas = tamagno[0]\n",
    "num_columns = tamagno[1]\n",
    "\n",
    "print(tamagno)\n",
    "print(\"Esta tabla tiene {} filas y {} columnas\".format(num_filas, num_columns))"
   ]
  },
  {
   "source": [
    "^ la función `shape` regresa un tipo de archivo llamado *tuple* o *tupla*, que consiste en una lista ordenada de objetos. Podemos comprobarlo simplemente imprimiendo el tipo de dato:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(tamagno))"
   ]
  },
  {
   "source": [
    "### ¿Cuáles columnas tenemos en nuestro DataFrame?\n",
    "\n",
    "Como habrás visto, cuando imprimimos los datos del DataFrame, no nos presenta toda la información, por eso aparecen tres puntos suspensivos entre las columnas.\n",
    "\n",
    "Para saber el nombre de cada columna (y poder hacer búsquedas posteriormente) podemos utilizar la función `columns` de pandas:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "source": [
    "### ¿Qué datos tenemos en el DataFrame?\n",
    "\n",
    "Ahora sabemos el tamaño del DataFrame y el nombre de sus columnas. Pero, para hacer operaciones (como sumar, restar, hallar medias, etc.) tendremos que identificar cuáles son los tipos de datos que tenemos en nuestro DataFrame.\n",
    "\n",
    "Para ello, usaremos la función `dtypes` de pandas:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "source": [
    "^ Analiza los tipos de datos que tenemos en el DataFrame:\n",
    "\n",
    "* int64 = números enteros\n",
    "* float64 = números decimales\n",
    "* object = objeto de pandas (puede ser un diccionario, un numpy.array, una lista...)\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Pandas incluso nos permite hacer análisis muy rápidos de la información, como por ejemplo, hallar la desviación estándar de cada columna (en la que existan datos de intervalo):"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.std())"
   ]
  },
  {
   "source": [
    "# Manipular la información del DataFrame\n",
    "\n",
    "## ¿Qué información hay en una columna específica?\n",
    "\n",
    "Para ver qué información tiene una columna específica vamos a utilizar el siguiente método:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_nombre = df['sexo']\n",
    "\n",
    "print(col_nombre[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.loc[df['sexo'] == \"Mujer\"])\n"
   ]
  },
  {
   "source": [
    "¿Y si queremos ver por sexo y localidad?\n",
    "\n",
    "Utilizamos el mismo método (`loc`) pero ahora buscamos dos valores. Si lo verbalizamos es como pedirle a la máquina:\n",
    "\n",
    "Búscame en el DataFrame todos los valores en los que el sexo sea 'Mujer' y el nombre de la localidad (`nomgeo`) sea igual a 'Azcapotzalco'. En código será lo siguiente:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_loc = df.loc[(df['sexo'] == 'Mujer') & (df['nomgeo'] == 'Azcapotzalco')]\n",
    "print(sex_loc[:10])"
   ]
  },
  {
   "source": [
    "# ¡A visualizar!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "data_canada = px.data.gapminder().query(\"country == 'Canada'\")\n",
    "fig = px.bar(data_canada, x='year', y='pop')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupyter_dash import JupyterDash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necesario si corre en Binder\n",
    "\n",
    "JupyterDash.infer_jupyter_proxy_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir la aplicación\n",
    "\n",
    "app = JupyterDash(__name__)\n",
    "\n",
    "server = app.server\n",
    "\n",
    "app.layout = html.Div([\n",
    "    dcc.Graph(figure=fig)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.run_server(mode=\"inline\")"
   ]
  },
  {
   "source": [
    "# Referencias\n",
    "\n",
    "## Documentación\n",
    "\n",
    "* [The Programming Historian: Python](https://programminghistorian.org/es/lecciones/?topic=python)\n",
    "* [pandas documentation](https://pandas.pydata.org/pandas-docs/stable/index.html)\n",
    "* [plotly open source graphing libraries](https://plotly.com/python/)\n",
    "* [dash open-source](https://dash.plotly.com/)\n",
    "\n",
    "\n",
    "## Bibliografía\n",
    "\n",
    "* McKinney, Wes. *Python for data analysis: data wrangling with pandas, NumPy, and IPython*. Second edition, O’Reilly Media, Inc, 2018.\n",
    "* Pajankar, Ashwin. *Practical Python Data Visualization: A Fast Track Approach to Learning Data Visualization with Python*. 2021.\n",
    "* Stepanek, y Suresh John. *Thinking in Pandas*. Apress, 2020. Open WorldCat, https://link.springer.com/10.1007/978-1-4842-5839-2.\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}